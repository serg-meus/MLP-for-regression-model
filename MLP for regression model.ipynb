{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the requiered libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"autos mpg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['HP'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The HP column is in a string str format so we will be requiered to convert it into a numeric int or float format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HP'] = pd.to_numeric(df['HP'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The HP column has 6 blank cells and therefore it is worth it to skip the rows where these empty spaces are. The other columns are completed and do not have null values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 0, how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MPG is our target value, labels, or the number that we want to predict with our neural network. And NAME column contains the names of every car in a string format. As a result, we will separate the MPG column into another df and we will explore the Name column to see how many unique values there are and if it can be used as a feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df['MPG']\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_min = y.min()\n",
    "mpg_max = y.max()\n",
    "mpg_avg = y.mean()\n",
    "mpg_std = y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {'Statistics of MPG': [mpg_min, mpg_max, mpg_avg, mpg_std]}\n",
    "stat_mpg = pd.DataFrame(data=summary, index=['Min', 'Max','Avg','Std'])\n",
    "stat_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_mpg.plot(kind='bar', color='goldenrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mpg_avg-mpg_std, ' - ', mpg_avg, ' + ', mpg_avg+mpg_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is important information to take into consideration because Miles per Gallon is our target value. The average MPG of all the dataset's car is 23.45 with a standard deviation of 7.81. Practically, it can be said that it is normal that a car performs from 15.64 to 31.25 miles per gallon. Data points outside this range can be considered outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('NAME', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 301 unique categoric values in the NAME column, which represents the 77% of the 392 records. Therefore, it is decided to skip it and not use it as a feature to train our neural network. Lets see the correlation of the other variables and the MPG column so we can select the best features!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot = True, cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can perceive that each of the seven features: cylinders, displacement, HP, weight, acceleration, year, and origin, has a high level of correlation with MPG variable. As a result, we will use these seven features to train our model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('MPG', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets use Min Max Normalization to normalize all the seven features, transforming their values into a scale between 0 and 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    data_normalized = ((dataset-dataset.min())/(dataset.max()-dataset.min()))\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalize(df)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas series to Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_X = features[['CYLINDERS','DISPLACEMENT', 'HP', 'WEIGHT', 'ACCELERATION', 'YEAR', 'ORIGIN']].to_numpy()\n",
    "numpy_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_y = y.to_numpy()\n",
    "numpy_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a train (80%) and a test (20%) set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(numpy_X, numpy_y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy arrays to Pytorch tensors train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the train set.\n",
    "tensor_X = torch.from_numpy(train_X).float() \n",
    "tensor_y = torch.from_numpy(train_y).float() \n",
    "print(tensor_X.shape, tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_y = tensor_y.unsqueeze(1)\n",
    "print(tensor_X.shape, tensor_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = Data.TensorDataset(tensor_X, tensor_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a dataloader to load it in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 45 # we will have 8 iterations in each epoch. 313 data divided by 45 data \n",
    "           # per batch, is equal to 7 batches or iterations to complete one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Data.DataLoader(\n",
    "    dataset = torch_dataset,      # torch TensorDataset format\n",
    "    batch_size = batch,           # mini batch size\n",
    "    shuffle=True,                 # random shuffle for training\n",
    "    num_workers=2,                # subprocesses for loading data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a nn, optimizer, and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(7, 10), # first layer\n",
    "   nn.ReLU(),\n",
    "   nn.Linear(10, 10), # second layer\n",
    "   nn.ReLU(),\n",
    "   nn.Linear(10, 10), # third layer\n",
    "   nn.ReLU(),\n",
    "   nn.Linear(10, 1)   # fourth layer\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lst = []\n",
    "for epoch in range(1, 101):\n",
    "    batch = 1\n",
    "    print(\"Epoch\", epoch)\n",
    "    for step, (batch_x, batch_y) in enumerate(loader): \n",
    "        var_X, var_y = Variable(batch_x), Variable(batch_y)\n",
    "        prediction = model(var_X)\n",
    "        rmse_loss = torch.sqrt(loss_function(prediction, var_y))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        rmse_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_lst.append(float(rmse_loss))\n",
    "        print(\"Batch: \", batch, \", loss: \", rmse_loss)\n",
    "        batch += 1\n",
    "    print(\"Result of the last epoch's batch: \", rmse_loss)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss per epoch in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3)) \n",
    "plt.plot(loss_lst, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Numpy arrays to Pytorch tensors for testing set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the test set.\n",
    "tensor_X_test = torch.from_numpy(test_X).float() \n",
    "tensor_y_test = torch.from_numpy(test_y).float() \n",
    "print(tensor_X_test.shape, tensor_y_test.shape)\n",
    "\n",
    "tensor_y_test = tensor_y_test.unsqueeze(1)\n",
    "print(tensor_X_test.shape, tensor_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_X_test = Variable(tensor_X_test)\n",
    "var_y_test = Variable(tensor_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do predictions of the testing set and calculate the RMSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model(var_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_loss = torch.sqrt(loss_function(predictions_test, var_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Root Mean Square Error of the testing set is 2.8, and since it is similar to the RMSE of the training set, we can conclude that there is not overfitting, perfect! An RMSE of 2.8 means that on average our model will do a prediction with a ± 2.8 error of miles per gallon. This is considered a satisfying result because 2.8 represents 12% out of the MPG average of our complete dataset and because 2.8 is lower than the MPG standard deviation of our whole dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the predictions against target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictions_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = var_y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,3)) \n",
    "plt.plot(y_pred, c='blue', label=\"predictions\")\n",
    "plt.plot(y_real, c='red', label=\"target\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict JUST one data with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = var_X_test[0]\n",
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Target value: \", var_y_test[0])\n",
    "print(\"Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When predicting only one data, the first one of the testing set, it can be seen that the target or real value is 28 MPG and that the prediction is 26.7. The prediction is really close and has an absolute error of 1.3 MPG or a percentage error of 4.6%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_mlp",
   "language": "python",
   "name": "auto_mlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
